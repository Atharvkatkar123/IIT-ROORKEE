{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7edb8-9876-44ee-b581-4c7ee7bfc3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5fcb2-ea55-464c-a3b5-a7a9e26edaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"This is an example sentence.\")\n",
    "\n",
    "\n",
    "embeddings = doc.vector\n",
    "print(embeddings)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314d935-59ba-46ae-bc01-515c49c4ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "\n",
    "words = [\"apple\", \"banana\", \"jet\", \"car\", \"truck\", \"bicycle\"]\n",
    "\n",
    "\n",
    "embeddings = [nlp(word).vector for word in words]\n",
    "\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259a091-57f7-475b-af54-c200cc76973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "mag_car_embeddings = sqrt(sum(car_embeddings[i]*car_embeddings[i] for i in range(len(car_embeddings))))\n",
    "mag_truck_embeddings = sqrt(sum(truck_embeddings[i]*truck_embeddings[i] for i in range(len(truck_embeddings))))\n",
    "dot_product = sum(car_embeddings[i]*truck_embeddings[i] for i in range(len(car_embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02215bd6-962e-4c62-aa7d-95aaf53a71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = dot_product/ (mag_car_embeddings * mag_truck_embeddings)\n",
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036d3d4-5eb7-49b9-9ffa-5c832ea88868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input\n",
    "import numpy as np\n",
    "\n",
    "input_word = input(\"Enter Word: \")\n",
    "\n",
    "embedding2 = nlp(input_word).vector\n",
    "\n",
    "Wordlist = [\"bus\", \"truck\", \"plane\", \"boat\", \"bicycle\", \"ship\", \"cat\", \"dog\", \"jet\", \"apple\", \"banana\", \"potato\", \"ufo\",\"war\",\"building\",\"bomb\",\"husband\"]\n",
    "\n",
    "similarities = []\n",
    "\n",
    "for i in Wordlist:\n",
    "    embedding1 = nlp(i).vector\n",
    "    similarity = cosine_similarity(embedding2, embedding1)\n",
    "    similarities.append((i, similarity))\n",
    "\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 3 similar words to '{}':\".format(input_word))\n",
    "for word, similarity in similarities[:3]:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b727d-cfed-4d81-bd3f-79e23f057610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "    mag_vec1 = sqrt(sum(a * a for a in vec1))\n",
    "    mag_vec2 = sqrt(sum(b * b for b in vec2))\n",
    "    return dot_product / (mag_vec1 * mag_vec2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1cad4-0823-495b-b300-ac219c678b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "# Group Wordlist by categories\n",
    "categories = {\n",
    "    \"vehicles\": [\"bus\", \"truck\", \"plane\", \"boat\", \"bicycle\", \"ship\", \"jet\", \"ufo\"],\n",
    "    \"animals\": [\"cat\", \"dog\"],\n",
    "    \"fruits\": [\"apple\", \"banana\", \"potato\"],\n",
    "    \"others\": [\"war\", \"building\", \"bomb\"]\n",
    "}\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "    mag_vec1 = sqrt(sum(a * a for a in vec1))\n",
    "    mag_vec2 = sqrt(sum(b * b for b in vec2))\n",
    "    return dot_product / (mag_vec1 * mag_vec2)\n",
    "\n",
    "\n",
    "# Get user input\n",
    "input_word = input(\"Enter Word: \").lower()\n",
    "\n",
    "# Predict the category using simple logic\n",
    "input_category = next(\n",
    "    (category for category, words in categories.items() if input_word in words),\n",
    "    \"others\"\n",
    ")\n",
    "\n",
    "# Filter Wordlist based on the predicted category\n",
    "filtered_wordlist = categories.get(input_category, [])\n",
    "\n",
    "# Calculate embeddings only for the filtered Wordlist\n",
    "try:\n",
    "    embedding2 = nlp(input_word).vector\n",
    "    similarities = [\n",
    "        (word, cosine_similarity(embedding2, nlp(word).vector))\n",
    "        for word in filtered_wordlist\n",
    "    ]\n",
    "\n",
    "    # Sort and display results\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"\\nTop 3 similar words to '{input_word}':\")\n",
    "    for word, similarity in similarities[:3]:\n",
    "        print(f\"{word}: {similarity:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error calculating similarities: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
